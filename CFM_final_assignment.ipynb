{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pZMUYIE8AQO"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Math, Latex\n",
        "\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Assignment\n",
        "### Team Number: 3\n",
        "### Team Member Names: Jeffrey Zhao, Bethany Liu, Ray Wang\n",
        "### Team Strategy Chosen: Safe"
      ],
      "metadata": {
        "id": "u3LRw04Frhun"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgox0l1nnJyI"
      },
      "source": [
        "Our team decided to aim for the **SAFEST** portfolio.\n",
        "\n",
        "The overall thought process behind our solution combines different key topics and calculations that we've learned throughout this course. Strategies we thought of to obtain the safest portfolio include:\n",
        "\n",
        "- **SMALLEST** standard deviation\n",
        "- **SMALLEST** beta\n",
        "- most **NEGATIVELY CORRELATED** stocks\n",
        "- the **MOST** stocks as possible (22) (diversification)\n",
        "\n",
        "These ideas will be seen and expanded upon throughout the rest of our code.\n",
        "Here is a brief overview:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rti0aIErlxJ5"
      },
      "source": [
        "Blueprint of the code:\n",
        "- Read in CSV File\n",
        "- Get rid of tickers that don't meet requirements\n",
        "- Calculate standard deviation\n",
        "- Calculate beta\n",
        "- Determine optimal portfolio by taking the 26 stock of smallest std + beta value\n",
        "- Calculate correlation between each stock and get rid of 4 stocks with highest correlation\n",
        "- Calculate optimal weightings on each stock\n",
        "- Generate final portfolio\n",
        "- Test portfolio\n",
        "\n",
        "(Side note: Although it was discussed, our team did not decide to try and earn back our transaction fees. We decided that in the grand scheme of things, if we buy 20 stocks, the fee will only be $\\$100$ which is extremely minimal compared to our $\\$750000$ portfolio. ($\\$100$ is approximately 0.013% of $\\$750000$). Furthermore, we also tried looking at investing in different industries, however, .info is broken.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "LNCpO0MqzdzW",
        "outputId": "b634a3bc-2445-43bc-feac-d513099cc338"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c929a342cd17>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Read in CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtickers_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tickers.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#dataframe for tickers file, change to 'Tickers' after we finish the code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtickers_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtickers_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Tickers.csv'"
          ]
        }
      ],
      "source": [
        "# Read in CSV file and filter out tickers that do not meet the requirements\n",
        "\n",
        "# Requirements:\n",
        "# - Stock must be denominated in either USD or CAD\n",
        "# - Stocks must have an average monthly volume of at least 150,000 shares between Jan 1 - Oct 31, 2023\n",
        "# - Stocks must have at least 18 trading days\n",
        "\n",
        "# Read in CSV file\n",
        "tickers_data = pd.read_csv('Tickers.csv', header=None) #dataframe for tickers file, change to 'Tickers' after we finish the code\n",
        "tickers_data.set_index(tickers_data.columns[0], inplace=True)\n",
        "\n",
        "# using these dates for data for now, can be changed later\n",
        "start_date = '2023-01-01'\n",
        "end_date = '2023-10-31'\n",
        "\n",
        "# create function to get data of every stock\n",
        "print(\"Please ignore error messages from yfinance\")\n",
        "\n",
        "def get_stock_data(ticker_df):\n",
        "  complete_stock_data = pd.DataFrame()\n",
        "  for i in ticker_df.index: # for loop to get every element of the dataframe\n",
        "    ticker = yf.Ticker(i)\n",
        "    stock_history = ticker.history(start=start_date, end=end_date)\n",
        "    if stock_history.empty:\n",
        "      continue\n",
        "    currency = ticker.fast_info['currency']\n",
        "\n",
        "    # ignore stocks that have monthly volume of less than 150000 and stocks that are not listed in cad or usd\n",
        "    if (monthly_volume(stock_history)>150000 and (currency == 'CAD'or currency == 'USD')):\n",
        "        complete_stock_data[i] = stock_history.Close.pct_change()\n",
        "\n",
        "  complete_stock_data.index = complete_stock_data.index.date\n",
        "\n",
        "  return complete_stock_data\n",
        "\n",
        "# create function to get the average monthly volume from january 1st to october 31st, get rid of months that have less than 18 trading days\n",
        "def monthly_volume(df):\n",
        "  min_trading_days = 18\n",
        "  trading_days_per_month = df.resample('M').size() # find number of trading days per month\n",
        "  valid_months = trading_days_per_month[trading_days_per_month >= min_trading_days].index # check if the number of days is greater than 18\n",
        "\n",
        "  # compute average volume\n",
        "  total_volume = 0\n",
        "  for month in valid_months:\n",
        "     total_volume += df[df.index.month == month.month].Volume.mean()\n",
        "  return total_volume/len(valid_months)\n",
        "\n",
        "# main\n",
        "complete_portfolio = get_stock_data(tickers_data)\n",
        "print(\"Complete portfolio of all the stocks in the ticker file:\", '\\n')\n",
        "complete_portfolio.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swL_nmkOxAOF"
      },
      "source": [
        "**Calculating the Standard Deviation**\n",
        "\n",
        "From the modules, we learned that the standard deviation of a stock is the calculation of a stocks volatility (the tendancy for the stock price to change). So in order to achieve the safest portfolio (least change), we want to have stocks with the lowest standard deviation. Therefore, we started off by calculating the standard deviation of the percentage returns of each stock in order to compare each of their volatilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhnV3AKfs3Hq"
      },
      "outputs": [],
      "source": [
        "# create function to calculate the standard deviation\n",
        "def standard_deviation(df):\n",
        "  std = pd.DataFrame()\n",
        "  std = df.std()\n",
        "  return std\n",
        "\n",
        "print(\"Standard deviation of the percentage returns for each stock in the portfolio\")\n",
        "display(standard_deviation(complete_portfolio))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQclP4_P19kB"
      },
      "source": [
        "**Calculating the Beta**\n",
        "\n",
        "We also learned that the beta is also a measure of the volaility of a security's return. However, it measures it in comparison to the market. We decided to consider this since we want our stocks to be less correlated to the market, meaning that it would be less influenced by the fluctuations in the market. (For the market, we decided to use the S&P 500 as it would give the best indication to how the market is doing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsTtt_fD27E0"
      },
      "outputs": [],
      "source": [
        "# graph the closing prices of the market\n",
        "start_date1 = '2023-01-01'\n",
        "end_date1 = '2023-10-31'\n",
        "investment = 750000\n",
        "\n",
        "# import S&P 500\n",
        "MarketIndex='^GSPC'\n",
        "Ticker2 = yf.Ticker(MarketIndex)\n",
        "MarketIndex_hist = Ticker2.history(start=start_date, end=end_date)\n",
        "shares = investment/MarketIndex_hist['Close'].iloc[0]\n",
        "Market_portfolio = MarketIndex_hist['Close']*shares\n",
        "Marketdf = MarketIndex_hist['Close'].pct_change()\n",
        "Marketdf.index = Marketdf.index.date\n",
        "\n",
        "plt.figure(figsize = (13,6))\n",
        "plt.plot(Market_portfolio, label = \"S&P 500\")\n",
        "plt.title(f\"Portfolio Values for the S&P 500 between {start_date1} and {end_date1}\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"S&P 500 Portfolio Values (USD)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"The standard deviation of the S&P 500 is\", MarketIndex_hist['Close'].pct_change().std())\n",
        "print(f\"The capital gain of the S&P 500 between {start_date1} and {end_date1} is {abs(Market_portfolio.iloc[-1] - Market_portfolio.iloc[0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teTgB8BY7J3q"
      },
      "source": [
        "From above, we can see that the market seems to change constantly between the beginning of this year. So, we decided that it is not optimal for the stocks we choose to be highly correlated with the market as it would then also be as volatile as the market."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9JQT8fAqPWS"
      },
      "outputs": [],
      "source": [
        "# calculate the beta\n",
        "# takes in a dataframe with the close prices and outputs a dataframe of one row containing all the betas for each stock\n",
        "'''\n",
        "Beta \t Meaning\n",
        "1.0\tThe stock moves in line with the broader market\n",
        "2.0\tThe stock moves twice as much as the broader market\n",
        "0.0\tThe stock's moves donâ€™t correlate with the broader market\n",
        "-1.0\tThe stock moves in the opposite direction of the broader market\n",
        "'''\n",
        "\n",
        "def beta(df):\n",
        "  #create dataframe for the beta values\n",
        "  betadf = pd.DataFrame()\n",
        "  for i in df.columns:\n",
        "    #create a dataframe with a single stocks prices and the market index\n",
        "    prices = pd.DataFrame()\n",
        "    prices[i] = df[i]\n",
        "    prices[MarketIndex] = Marketdf\n",
        "    #calculate variance of market\n",
        "    MarketVar = prices[MarketIndex].var()\n",
        "    #drop first row since NA\n",
        "    prices.drop(index=prices.index[0], inplace=True)\n",
        "    #calculate beta which returns a 2x2 dataframe\n",
        "    betacalc = prices.cov()/MarketVar\n",
        "    #select the value for the beta of the selected stock\n",
        "    betadf[i] = pd.Series(betacalc.iat[0,1])\n",
        "\n",
        "  return betadf\n",
        "\n",
        "print(\"The beta for each stock is:\", '\\n')\n",
        "display(beta(complete_portfolio))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCD-4sMg-hJL"
      },
      "source": [
        "**Adding the Standard Deviation and Beta**\n",
        "\n",
        "After calculating the standard deviation and beta of each stock, we decided to add the two values together to determine the extent of its volatility and compare it with the other stocks. We chose to priioritize the standard deviation of the stock more than its beta since the standard deviation is more of an indicator of a stock's volatility than its beta. Therefore, we chose a weighting of 70% on the standard deviation and 30% on the beta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY0KL0vWu-XE"
      },
      "outputs": [],
      "source": [
        "# add standard deviation and beta\n",
        "\n",
        "# market movement is not as impactful as the volatility of the stock itself so put weighting on each in relation to importance\n",
        "std_weight = 0.7\n",
        "beta_weight = 0.3\n",
        "\n",
        "# function to calculate the sum of the standard deviation and beta\n",
        "def add_std_and_beta(std, beta):\n",
        "  std_and_beta = pd.DataFrame()\n",
        "  std_and_beta = std*std_weight*100 + abs(beta)*beta_weight\n",
        "  return std_and_beta\n",
        "\n",
        "std_and_beta = add_std_and_beta(standard_deviation(complete_portfolio), beta(complete_portfolio))\n",
        "display(std_and_beta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufe3f0KzF9CE"
      },
      "source": [
        "After calculating the sum, we then took the top 24 stocks with the lowest standard deviation and beta to filter out stocks with the highest volatility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPXTTNBUwyPQ"
      },
      "outputs": [],
      "source": [
        "# get the top 24 stocks with least standard deviation and beta\n",
        "# returns a dataframe with the list of 24 tickers from the least volatile to most volatile based off our calculations\n",
        "portfolio = pd.DataFrame()\n",
        "def get_portfolio(std_and_beta):\n",
        "   std_and_beta = std_and_beta.iloc[0, :].sort_values()\n",
        "   if len(std_and_beta) >= 22:\n",
        "    portfolio = pd.DataFrame(std_and_beta.head(min(24, len(std_and_beta))))\n",
        "   else:\n",
        "    portfolio = std_and_beta\n",
        "\n",
        "\n",
        "   return portfolio\n",
        "\n",
        "# main\n",
        "generated_portfolio = get_portfolio(std_and_beta)\n",
        "generated_portfolio.rename(columns={0: 'Std and Beta value'}, inplace=True)\n",
        "display(generated_portfolio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzH3pVloHrUo"
      },
      "source": [
        "**Calculating the Correlation**\n",
        "\n",
        "Next, we calculated the correlation between each of our 24 chosen stocks. To obtain the safest portfolio, it is important to have a diversified portfolio, meaning that the stocks that we choose should have as minimal of a correlation as possible (optimal would be a perfect negative correlation, which means 0 capital gain/loss, however that is extremely difficult to obtain). After calculating the correlation between each stock, we get rid of 2 stocks (one in each pair) of the highest correlation in attempts to divsersify the industries of the different stocks (the higher the correlation, the more likely they are to be in the same industry)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7b45-fIGzxi"
      },
      "outputs": [],
      "source": [
        "# calculate correlation between each chosen stock\n",
        "correlation = get_stock_data(generated_portfolio).corr()\n",
        "\n",
        "# filter out stocks with a correlation greater than 0.75 or 1 (same stock)\n",
        "correlation = (correlation[(correlation<.75) | (correlation == 1)])\n",
        "print(\"The beginning of the dataframe containing the correlations between the stocks is:\")\n",
        "display(correlation.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-OnNEbpNF0x"
      },
      "source": [
        "**Removing high correlation stocks**\n",
        "\n",
        "We go through the portfolio in reverse by considering the columns of the correlation dataframe, If there is a NaN value in the column, it means this ticker has a high correlation with another ticker. We then compare the row indices for when there is NaN value, and if the row indices are still in the portfolio, we remove the column ticker from the portfolio. If the row indices do not appear in the portfolio, it means it has aleady been removed previously. In this case we do not remove the column because we still want to keep at least one stock from a pair that has high correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWv_ySCy1ASY"
      },
      "outputs": [],
      "source": [
        "columns_reverse = list(reversed(correlation.columns))\n",
        "for i in columns_reverse:\n",
        "  if correlation[i].isnull().any() and len(generated_portfolio)>=10: # if there is a correlation value that is higher than 0.75, than it would be filtered out as NaN in the table\n",
        "    null_indices = correlation.loc[correlation[i].isnull()].index # find the row indices where the the correlation is higher than 0.75\n",
        "    common_indices = generated_portfolio.index.intersection(null_indices) # find the row indices that are also in the portfolio\n",
        "    if common_indices.size != 0: # if there's no intersection, it means the row index has already been removed from the portfolio, so no need to remove the column as well\n",
        "      print('The removed ticker is', i)\n",
        "      generated_portfolio = generated_portfolio.drop(i) # if common row indices is not empty, get rid of the ticker of the column\n",
        "\n",
        "if len(generated_portfolio>22): # after eliminating the high correlation stocks, if the number of stocks we have is greater than the required amount of 22, just take only the first 22 stocks\n",
        "  generated_portfolio = generated_portfolio.head(22)\n",
        "print('The updated portfolio after removing high correlation stocks:')\n",
        "display(generated_portfolio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84BfDNzV9EaT"
      },
      "source": [
        "**Calculating the Optimal Weighting on Each Stock**\n",
        "\n",
        "After removing the high correlation stocks, we are left with the stocks we want to keep in our portfolio. The way we are going to determine weighting is to linearly increase the weighting every stock starting from the most volatile one. We are giving the volatile stocks less weighting so that it has less of an influence on the portfolio. The formula to generate the weighting is determined by the arithmetic sum formula with the sum being 100 and the starting value being 100/(2*number of tickers)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvXjlC5L8jqW"
      },
      "outputs": [],
      "source": [
        "# determine weighting/percentage of each stock\n",
        "# using arithmetic sequence sum formula Sn = n/2(2a+(n-1)d), calculate the difference in weighting between each stock\n",
        "# to evenly space out weighting of every stock, with the most volatile ones being the least weighted, least volatile being most weighted\n",
        "# choose starting value, a, to be the minimum weighted value, 100/(2*n), as stated by the rules\n",
        "n=len(generated_portfolio) # number of stocks\n",
        "S = 100 # weighting has to add up to 100%\n",
        "a = 100/(2*n)\n",
        "d = ((S*2/n)-2*a)/(n-1)\n",
        "print(\"Difference in weighting between each stock:\", d)\n",
        "print(\"Weighting of the most volatile stock:\", a)\n",
        "print(\"Weighting of the least volatile stock:\", a+21*d)\n",
        "\n",
        "def create_final_portfolio(df):\n",
        "  Portfolio_Final = pd.DataFrame(columns=['Ticker', 'Price', 'Currency', 'Shares', 'Values', 'Weight'], index=range(1, len(df)+1))\n",
        "  start_date = '2023-11-21'\n",
        "  end_date = '2023-11-21'\n",
        "  usd_to_cad = yf.Ticker('USDCAD=x')\n",
        "  exchange_rate = usd_to_cad.fast_info['previousClose']\n",
        "\n",
        "  investment = 750000\n",
        "  count = 1\n",
        "  for i in df.index:\n",
        "    investment = investment - 4.95 # subtract out the fees for the buying the stock\n",
        "\n",
        "    ticker = yf.Ticker(i)\n",
        "    stock_price = ticker.fast_info['previousClose'] # take the last close price of the stock\n",
        "    currency = ticker.fast_info['currency']\n",
        "    weight = a+(n-count)*d # calculates weighting of the stock\n",
        "\n",
        "    Portfolio_Final.loc[count, 'Ticker'] = i\n",
        "    Portfolio_Final.loc[count, 'Price'] = stock_price\n",
        "    Portfolio_Final.loc[count, 'Currency'] = currency\n",
        "    Portfolio_Final.loc[count, 'Weight'] = round(weight,2)\n",
        "    if currency == 'USD':\n",
        "     stock_price = stock_price*exchange_rate # turn stock price into CAD\n",
        "\n",
        "    shares_values = investment*weight/100 # find value of this stock in CAD in the portfolio\n",
        "    num_shares = shares_values/stock_price\n",
        "    Portfolio_Final.loc[count, 'Shares'] = round(num_shares,2)\n",
        "    Portfolio_Final.loc[count, 'Values'] = round(shares_values,2)\n",
        "\n",
        "    count += 1\n",
        "\n",
        "  columns_to_sum = Portfolio_Final[['Values','Weight']]\n",
        "  Portfolio_Final.loc['Total'] = columns_to_sum.sum(axis=0)\n",
        "  return Portfolio_Final\n",
        "  #Ticker, Price, Currency, Shares, Value, Weight. Ticker will be the ticker your code selected, Price is the price on November 25, 2023,\n",
        "  #Currency is either USD or CAD, Shares is the number of shares you purchased of that stock,\n",
        "  #Value is the total value of those shares, and Weight is the weight that the value of shares represents relative to the value of your portfolio\n",
        "\n",
        "final_portfolio = create_final_portfolio(generated_portfolio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpCC9NEL8BtU"
      },
      "source": [
        "**Test Runs**\n",
        "\n",
        "Now that we have our final portfolio, we need to test to see whether or not it works. We do this through building our portfolio by investing the determined weighting on each stock and adding the returns for of each invetment. We then compute the overall capital gain/loss and the standard deviation of the portfolio to compare the results.\n",
        "\n",
        "Our test trials consist of the results of the most recent week, month and year to guage how well our code works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyVdoPPcH5rj"
      },
      "outputs": [],
      "source": [
        "# Basic imports\n",
        "\n",
        "# begining investment\n",
        "investment = 750000 #(an estimation)\n",
        "\n",
        "# import chosen tickers\n",
        "test_tickers = final_portfolio['Ticker'].iloc[:-1].tolist()\n",
        "print(test_tickers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgg5v3pP7xaa"
      },
      "outputs": [],
      "source": [
        "# Test 1: 1 Week (2023-11-16 - 2023-11-23)\n",
        "\n",
        "# change dates here\n",
        "test1_start_date = '2023-11-25'\n",
        "test1_end_date = '2023-12-01'\n",
        "\n",
        "# get the closing prices of each ticker multiplied by the respective number of shares\n",
        "def get_test_portfolio(test_tickers, start_date, end_date):\n",
        "  closing = pd.DataFrame()\n",
        "  count = 0\n",
        "\n",
        "  for ticker in test_tickers:\n",
        "    hist = yf.Ticker(ticker).history(start = start_date, end = end_date)\n",
        "    shares = (final_portfolio['Weight'].iloc[count]*0.01*investment)/hist['Close'].iloc[0]\n",
        "    closing[ticker] = hist['Close']*shares\n",
        "    count += 1\n",
        "\n",
        "  return closing\n",
        "\n",
        "# main\n",
        "test1_portfolio = get_test_portfolio(test_tickers, test1_start_date, test1_end_date)\n",
        "test1_portfolio = test1_portfolio.dropna()\n",
        "test1_portfolio.index = test1_portfolio.index.date\n",
        "display(test1_portfolio.head())\n",
        "\n",
        "# get the final diversified portfolio\n",
        "final_test1_portfolio = test1_portfolio.sum(axis=1)\n",
        "display(final_test1_portfolio.head())\n",
        "\n",
        "def plot_portfolio(test_portfolio, start_date, end_date):\n",
        "  # beginning value - ending value\n",
        "  print(\"The capital gain/loss is,\", abs(test_portfolio.iloc[-1] - test_portfolio.iloc[0]))\n",
        "  print(\"The standard deviation of the final portfolio is\", test_portfolio.pct_change().std())\n",
        "\n",
        "  # plot graph\n",
        "  plt.figure(figsize = (13,6))\n",
        "  plt.plot(test_portfolio, label = \"Test Portfolio\")\n",
        "  plt.title(f\"Portfolio Values for the Test Tickers between {start_date} and {end_date}\")\n",
        "  plt.xlabel(\"Date\")\n",
        "  plt.ylabel(\"Test Portfolio Values (CAD)\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# main\n",
        "plot_portfolio(final_test1_portfolio, test1_start_date, test1_end_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nb8VpdZEIUkQ"
      },
      "outputs": [],
      "source": [
        "# Test 2: 1 Month (2023-10-01 - 2023-10-31)\n",
        "\n",
        "test2_start_date = '2023-10-01'\n",
        "test2_end_date = '2023-10-31'\n",
        "\n",
        "# get portfolio\n",
        "test2_portfolio = get_test_portfolio(test_tickers, test2_start_date, test2_end_date)\n",
        "test2_portfolio = test2_portfolio.dropna()\n",
        "test2_portfolio.index = test2_portfolio.index.date\n",
        "display(test2_portfolio.head())\n",
        "\n",
        "# get the final diversified portfolio\n",
        "final_test2_portfolio = test2_portfolio.sum(axis=1)\n",
        "display(final_test2_portfolio.head())\n",
        "\n",
        "# plot graph\n",
        "plot_portfolio(final_test2_portfolio, test2_start_date, test2_end_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXMMCqswJoeg"
      },
      "outputs": [],
      "source": [
        "# Test 3: (approximately) 1 Year (2023-01-01 - 2023-11-24)\n",
        "\n",
        "test3_start_date = '2023-01-01'\n",
        "test3_end_date = '2023-10-31'\n",
        "\n",
        "# get portfolio\n",
        "test3_portfolio = get_test_portfolio(test_tickers, test3_start_date, test3_end_date)\n",
        "test3_portfolio = test3_portfolio.dropna()\n",
        "test3_portfolio.index = test3_portfolio.index.date\n",
        "display(test3_portfolio.head())\n",
        "\n",
        "# get the final diversified portfolio\n",
        "final_test3_portfolio = test3_portfolio.sum(axis=1)\n",
        "\n",
        "display(final_test3_portfolio.head())\n",
        "\n",
        "# plot graph\n",
        "plot_portfolio(final_test3_portfolio, test3_start_date, test3_end_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoC4KMFpcK4x"
      },
      "source": [
        "**Comparing our portoflio with the S&P 500**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4CyOxqpcSO0"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize = (13,6))\n",
        "plt.plot(final_test3_portfolio.pct_change(), label = \"Generated Portfolio\")\n",
        "plt.plot(Market_portfolio.pct_change(), label = \"S&P 500\")\n",
        "plt.title(f\"Generated Portfolio Percentage returns vs S&P 500 Percentage returns between {test3_start_date} and {test3_end_date}\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Percentage Returns\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Results**\n",
        "\n",
        "From the 3 tests conducted above, it is clear to see that our portfolio does not reach a 0 return in any case. However, the standard deviation on all three are extremely low (Test 1: 0.002, Test 2: 0.008, Test 3: 0.006) indicating that our code is still works in finding a less volatile portfolio. Furthermore, when comparing the percentage returns of our portfolio with the percentage returns of the S&P 500, we can see that in general, our portfolio is less volatile."
      ],
      "metadata": {
        "id": "RqR9axWDpVNI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86G9FRZZWiBM"
      },
      "source": [
        "**Finishing Touches**\n",
        "\n",
        "After finalizing and testing the data required to create our safe portfolio, we can now output the final portfolio..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAWeNE4-3VAo"
      },
      "outputs": [],
      "source": [
        "display(final_portfolio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7368_AvVd35A"
      },
      "source": [
        "... and convert it to csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaoG8vCAG0hn"
      },
      "outputs": [],
      "source": [
        "# output to csv file\n",
        "Stocks_Final = final_portfolio[['Ticker', 'Shares']]\n",
        "Stocks_Final = Stocks_Final.drop(index = 'Total')\n",
        "\n",
        "display(Stocks_Final)\n",
        "\n",
        "Stocks_Final.to_csv('Stocks_Group_03.csv', index = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contribution Declaration\n",
        "\n",
        "The following team members made a meaningful contribution to this assignment:\n",
        "\n",
        "Jeffrey Zhao, Bethany Liu, Ray Wang"
      ],
      "metadata": {
        "id": "bDkZkXg-su_p"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h27h6KyEeMcu"
      },
      "source": [
        "**THE END**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}